ㅈㅎㄷ # 뉴스 분석 파이프라인: 변경 전/후 상세 비교 보고서

이 보고서는 뉴스 분석 프로젝트 '겜보(Gembo)'의 AI 서버에서 구현된 키워드 추출 및 기사 분석 파이프라인이 어떻게 발전했는지, 각 단계에서 어떤 기술과 알고리즘이 사용되었고 어떤 개선이 이루어졌는지를 상세히 비교합니다.

---

## 🔵 파이프라인 1: 키워드 추출

**목표**: 기사 본문에서 핵심 키워드를 추출하는 것.

### 1-1. 변경 전: TF-IDF 기반 통계적 추출

-   **사용한 기술/알고리즘**:

    -   `scikit-learn` 라이브러리의 `TfidfVectorizer` (추정)
    -   기본적인 텍스트 전처리 및 형태소 분석기 (예: `KoNLPy`)
    -   **핵심 원리**: 단어 빈도수(Term Frequency) 및 역문서 빈도(Inverse Document Frequency) 계산

-   **처리 방식 (추정)**:

    1.  기사 본문에서 모든 단어를 추출하고 토큰화합니다.
    2.  각 단어가 특정 기사 내에서 얼마나 자주 등장하는지 계산하여 TF(단어 빈도) 값을 구합니다.
    3.  사전에 정의된 대규모 문서 집합(코퍼스) 내에서 해당 단어가 얼마나 희귀하게 나타나는지 계산하여 IDF(역문서 빈도) 값을 구합니다.
    4.  TF와 IDF를 곱하여 `TF-IDF` 점수를 산출하고, 이 점수가 높은 단어를 핵심 키워드로 간주했습니다.

-   **한계점**:
    -   **의미/문맥 이해 불가**: '인공지능'과 'AI'를 서로 다른 단어로 취급하는 등 단어의 의미적 유사성을 파악하지 못했습니다.
    -   **위치 중요도 무시**: 기사 제목, 이미지 캡션, 본문 내 강조 구문 등 단어가 등장하는 위치의 중요도를 전혀 고려하지 않고 모든 텍스트를 동등하게 처리했습니다.
    -   **부적절한 키워드 추출**: 기사에는 자주 등장하지만 실제 핵심과는 거리가 먼 '자료', '뉴스', '제공' 같은 일반 명사가 상위 키워드로 추출될 가능성이 높았습니다.

---

### 1-2. 변경 후: 의미와 구조를 이해하는 하이브리드 추출 (현재 `NewsKeywordExtractor`)

-   **사용한 기술/알고리즘**:

    -   `BeautifulSoup` (HTML 파싱 및 구조 분석)
    -   `kiwipiepy` (고성능 한국어 형태소 분석 및 신조어 추출)
    -   `NetworkX` (단어 네트워크 그래프 생성 및 **PositionRank 알고리즘**)
    -   `SentenceTransformer (BAAI/bge-m3)` (단어/문서 임베딩 및 의미 유사도 계산)
    -   `numpy` (수치 계산)

-   **처리 방식 (현재)**:

    1.  **Step 1: 고도화된 크롤링 및 가중치 태깅**: `BeautifulSoup`을 사용하여 HTML을 파싱하고, 다음 기준에 따라 단어에 **위치 가중치**를 부여합니다.
        -   **언론사 제공 키워드 (NEW)**: 최고 가중치 6.0 (외부 전문가 지식 활용)
        -   기사 제목: 5.0
        -   이미지 캡션: 3.0
        -   강조 구문 (`<b>`, `<strong>`), 첫 문단: 2.0
        -   일반 본문: 1.0
    2.  **Step 2: Kiwi 형태소 분석 및 후보군 추출**: `kiwipiepy`를 사용하여 텍스트에서 명사(NNG, NNP)와 어근(XR)을 추출합니다. `kiwi.extract_add_words` 기능으로 신조어를 자동으로 인식하며, 불용어를 제거합니다.
    3.  **Step 3: 구조적 중요도 계산 (Advanced PositionRank)**: `NetworkX`로 단어 동시 등장 그래프를 생성하고, `PageRank` 알고리즘을 실행합니다. 이때 Step 1에서 부여한 '위치 가중치'를 `personalization` 파라미터로 반영하여, 구조적으로 중요한 위치의 단어가 더 높은 점수를 받도록 합니다.
    4.  **Step 4: 의미적 중요도 계산 (Semantic Embedding)**: `BAAI/bge-m3` 모델로 기사 전체와 각 후보 단어의 '의미 벡터'를 얻은 후, 코사인 유사도를 계산하여 **기사 전체의 주제와 의미적으로 가장 가까운 단어**를 찾아냅니다.
    5.  **Step 5: 최종 점수 산출 및 추출**: Step 3의 구조적 점수와 Step 4의 의미적 점수(각각 0-1로 정규화)를 `(구조적 점수 * 0.4) + (의미적 유사도 * 0.6)` 가중치로 합산하여 최종 점수를 산출합니다. 가장 높은 점수의 단어들을 최종 키워드로 선정합니다.

-   **개선된 점**:
    -   **의미/문맥 이해**: `BAAI/bge-m3` 임베딩 모델을 통해 단어의 표면적 형태를 넘어선 **의미적 유사성**을 파악하고, 기사 전체의 맥락과 밀접한 키워드를 추출합니다.
    -   **구조적 중요성 반영**: HTML 태그에 따른 가중치 부여와 `PositionRank` 알고리즘을 통해, **기사 내 단어의 위치가 가지는 중요도를 정확히 반영**하여 핵심 단어를 놓치지 않습니다.
    -   **전문가 지식 활용 (NEW)**: 언론사가 직접 지정한 키워드(메타 태그)를 우선적으로 고려하여, **사람의 판단을 시스템에 통합**시켜 키워드 품질의 신뢰도를 극대화합니다.
    -   **키워드 품질 향상**: 단순 빈도 기반의 TF-IDF가 놓치던 **진정한 핵심 키워드**를 찾아내어, 후속 분석 단계의 기초 데이터를 혁신적으로 개선합니다.

---

## 🔵 파이프라인 2: 기사 분석 및 요약

**목표**: 추출된 키워드를 활용하여 기사의 전문 용어를 정의하고, 최종 요약문을 생성하는 것.

### 2-1. 변경 전: 문맥 없는 LLM 질문과 부족한 재료

-   **사용한 기술/알고리즘**:

    -   `LangChain` (LLM 연동 프레임워크)
    -   `Ollama` (로컬 LLM 실행 환경)
    -   `MariaDB` (단어 정의 저장 DB)
    -   `BeautifulSoup` (API 텍스트 전처리)
    -   `HuggingFaceEmbeddings` (문서/정의 임베딩)
    -   `numpy` (유사도 계산)

-   **처리 방식 (추정)**:

    1.  TF-IDF 파이프라인에서 추출된 키워드 목록을 입력받습니다.
    2.  각 키워드에 대해 `MariaDB`에 저장된 정의를 1차로 검색합니다.
    3.  검색된 정의들과 기사 문맥 간의 유사도를 계산합니다.
    4.  가장 유사도가 높은 정의에 대해 LLM에게 "Context에 언급된 Word가 Definition에 설명된 그 대상(의미)을 지칭하는 것이 맞습니까?" 와 같이 **일반적인 질문 프롬프트**를 던져 검증합니다.
    5.  검증된 정의를 바탕으로 기사 요약 프롬프트를 구성하여 LLM에 요청합니다.

-   **한계점**:
    -   **"쓰레기가 들어오면 쓰레기가 나간다"**: 키워드 추출 파이프라인의 낮은 품질로 인해, 분석의 시작점부터 핵심 키워드가 누락되거나 부적절한 키워드가 포함될 수 있었습니다. 이는 이후의 DB 검색, LLM 검증, 요약 등 모든 과정의 품질을 저하시켰습니다.
    -   **LLM의 맹점**: LLM이 단어의 의미를 검증할 때, 해당 기사가 어떤 종류의 기사인지(예: '스포츠', '경제')에 대한 **구체적인 문맥 정보가 부족**했습니다. 이로 인해 '배'와 같은 동음이의어의 경우 잘못된 의미로 판단하거나, 추론에 오랜 시간이 걸릴 수 있었습니다.

---

### 2-2. 변경 후: 풍부한 문맥 기반의 지능형 추론 (현재 `AdvancedArticleAnalyzer`)

-   **사용한 기술/알고리즘**:

    -   동일 기술 스택 (`LangChain`, `Ollama`, `MariaDB` 등) + **메타데이터를 활용한 LLM 프롬프트 엔지니어링**

-   **처리 방식 (현재)**:

    1.  `NewsKeywordExtractor` 파이프라인에서 추출된 **고품질의 하이브리드 키워드 목록**을 입력받습니다.
    2.  각 키워드에 대해 `MariaDB`에서 정의를 검색하고, 기사 문맥과의 유사도를 계산하는 과정은 동일합니다.
    3.  **LLM 최종 검증 (강화)**: LLM에게 질문하는 프롬프트에 `self.metadata.get('category')`와 같은 **메타데이터 정보(예: "이 기사의 카테고리는 '국방'입니다.")를 명시적으로 추가**합니다. LLM은 이 정보를 바탕으로 단어의 의미를 훨씬 더 정확하게 판단하고 검증합니다.
    4.  **LLM 정의 정제 (강화 예정)**: `_refine_definition_with_llm` 함수에도 메타데이터를 활용하여 LLM이 더 정교하고 문맥에 맞는 정의를 생성하도록 유도할 수 있습니다.
    5.  **LLM 기사 요약 (강화 예정)**: 최종 기사 요약 시에도 메타데이터를 LLM 프롬프트에 포함시켜, 더 관련성 높고 핵심적인 내용을 중심으로 요약문을 생성하도록 합니다.

-   **개선된 점**:
    -   **고품질 입력**: 분석 파이프라인의 '재료'인 키워드 자체가 매우 정확해졌으므로, 이후 모든 LLM 기반 처리의 **기본 품질이 대폭 향상**되었습니다.
    -   **LLM의 지능 향상**: LLM이 단어의 의미를 검증하고 기사를 요약할 때, **'기사 카테고리'라는 강력한 문맥적 힌트**를 받아 훨씬 더 정확하고 신뢰성 있는 판단을 내립니다. (예: '국방' 기사에서 '함정'은 '군함'임을 즉시 인지).
    -   **시스템 신뢰도 극대화**: AI가 '사과'를 '과일'로 알아야 할지 '사과(apology)'로 알아야 할지 고민할 필요 없이, 명확한 문맥 가이드를 받으므로 **최종 결과물의 타당성이 대폭 상승**했습니다.

---

### 최종 종합 요약

| 파이프라인                | 변경 전                               | **변경 후 (현재)**                                                        | 핵심 개선점                                                      |
| :------------------------ | :------------------------------------ | :------------------------------------------------------------------------ | :--------------------------------------------------------------- |
| **1. 키워드 추출**        | TF-IDF (통계적 빈도, 단편적)          | **하이브리드** (의미, 구조, 관계, 전문가 지식 종합)                       | **의미 및 문맥 이해 능력 확보, 추출 키워드 품질 혁신**           |
| **2. 기사 분석/요약**     | 불분명한 키워드 입력, LLM의 문맥 부족 | **고품질 키워드 입력, LLM에 풍부한 문맥 제공**                            | **LLM 추론의 정확성과 신뢰성 극대화, 최종 결과물의 타당성 확보** |
| **사용한 기술 주요 변화** | `scikit-learn` 위주                   | `BeautifulSoup`, `kiwipiepy`, `NetworkX`, `SentenceTransformer` 추가/활용 | **최신 NLP 및 그래프 알고리즘 도입으로 분석 능력 강화**          |
| **시스템 전체**           | 통계 기반의 분절적이고 피상적인 처리  | **유기적으로 연결된 지능형, 맥락 인지 분석**                              | **인간의 이해에 가까운 정교하고 신뢰성 있는 뉴스 분석 서비스**   |
